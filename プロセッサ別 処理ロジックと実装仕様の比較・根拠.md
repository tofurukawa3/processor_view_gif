# ãƒ—ãƒ­ã‚»ãƒƒã‚µåˆ¥ å‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯ã¨å®Ÿè£…ä»•æ§˜ã®æ¯”è¼ƒãƒ»æ ¹æ‹ 

æœ¬è³‡æ–™ã§ã¯ã€10x10ï¼ˆåˆè¨ˆ100å€‹ï¼‰ã®ãƒ‡ãƒ¼ã‚¿è¡Œåˆ—ã‚’å‡¦ç†ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã«ãŠã„ã¦ã€å„ãƒ—ãƒ­ã‚»ãƒƒã‚µã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãŒæ¡ç”¨ã™ã‚‹è¨ˆç®—æ‰‹æ³•ã¨ãã®æŠ€è¡“çš„æ ¹æ‹ ã‚’å®šç¾©ã—ã¾ã™ã€‚

## 1. CPU (Central Processing Unit)

**å‡¦ç†æ–¹å¼: ã‚¹ã‚«ãƒ©å‡¦ç† (Scalar Processing)**

æ±ç”¨çš„ãªå‡¦ç†ã«ç‰¹åŒ–ã—ã¦ãŠã‚Šã€ãƒ•ã‚§ãƒƒãƒãƒ»ãƒ‡ã‚³ãƒ¼ãƒ‰ãƒ»å®Ÿè¡Œã®ã‚µã‚¤ã‚¯ãƒ«ã‚’å‘½ä»¤ã”ã¨ã«ç¹°ã‚Šè¿”ã—ã¾ã™ã€‚SISD (Single Instruction, Single Data) ãƒ¢ãƒ‡ãƒ«ã«åŸºã¥ãã¾ã™ã€‚

* **è¦–è¦šè¡¨ç¾:** ã€Œç‚¹ã€ãŒ1ãƒã‚¹ãšã¤ç§»å‹•ã™ã‚‹ã€‚
* **å®Ÿè£…ãƒ­ã‚¸ãƒƒã‚¯:** 2é‡ãƒ«ãƒ¼ãƒ—ã«ã‚ˆã‚‹å…¨è¦ç´ ã®é †æ¬¡èµ°æŸ»ã€‚
* **è¨ˆç®—é‡ (Theoretical Cycles):** **100**
* **ä¸»ãªç”¨é€”:** OSåˆ¶å¾¡ã€è¤‡é›‘ãªåˆ†å²å‡¦ç†ã€‚

> **ğŸ“š æ ¹æ‹ ãƒ»å‡ºå…¸**
>
> * **IntelÂ® 64 and IA-32 Architectures Software Developerâ€™s Manual**: åŸºæœ¬çš„ãªæ±ç”¨ãƒ¬ã‚¸ã‚¹ã‚¿ã‚’ç”¨ã„ãŸã‚¹ã‚«ãƒ©æ¼”ç®—ï¼ˆADD, MULç­‰ï¼‰ã®å®šç¾©ã€‚å‘½ä»¤ãƒã‚¤ãƒ³ã‚¿ãŒã‚·ãƒ¼ã‚±ãƒ³ã‚·ãƒ£ãƒ«ã«ãƒ¡ãƒ¢ãƒªä¸Šã®å‘½ä»¤ã‚’å®Ÿè¡Œã—ã¦ã„ãæŒ™å‹•ã«åŸºã¥ãã¾ã™ã€‚
> * **Hennessy & Patterson, "Computer Architecture: A Quantitative Approach"**: SISDã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãŠã‚ˆã³å‘½ä»¤ãƒ¬ãƒ™ãƒ«ã®ä¸¦åˆ—æ€§ï¼ˆILPï¼‰ã®é™ç•Œã«é–¢ã™ã‚‹è¨˜è¿°ã€‚

---

## 2. AVX2 (Advanced Vector Extensions)

**å‡¦ç†æ–¹å¼: SIMD (Single Instruction, Multiple Data)**

CPUã®æ‹¡å¼µå‘½ä»¤ã‚»ãƒƒãƒˆã§ã™ã€‚256ãƒ“ãƒƒãƒˆã®ãƒ¬ã‚¸ã‚¹ã‚¿ï¼ˆYMMãƒ¬ã‚¸ã‚¹ã‚¿ï¼‰ã‚’ä½¿ç”¨ã—ã€ä¾‹ãˆã°32ãƒ“ãƒƒãƒˆã®æµ®å‹•å°æ•°ç‚¹æ•°ï¼ˆfloatï¼‰ã§ã‚ã‚Œã°8å€‹ã‚’ã€1å‘½ä»¤ã§åŒæ™‚ã«æ¼”ç®—ã—ã¾ã™ã€‚

* **è¦–è¦šè¡¨ç¾:** ã€Œç·šï¼ˆè¡Œï¼‰ã€ãŒä¸Šã‹ã‚‰ä¸‹ã¸ç§»å‹•ã™ã‚‹ã€‚
* **å®Ÿè£…ãƒ­ã‚¸ãƒƒã‚¯:** ãƒ‡ãƒ¼ã‚¿ä¸¦åˆ—æ€§ã‚’ç”¨ã„ãŸãƒ™ã‚¯ãƒˆãƒ«æ¼”ç®—ï¼ˆãƒ«ãƒ¼ãƒ—ã®ã‚¢ãƒ³ãƒ­ãƒ¼ãƒªãƒ³ã‚°ã¨ãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼‰ã€‚
* **è¨ˆç®—é‡ (Theoretical Cycles):** **10** ($100 \div 10$ â€»ãƒ¢ãƒ‡ãƒ«ä¸Šã®ç°¡ç•¥åŒ–)
* **ä¸»ãªç”¨é€”:** ç”»åƒå‡¦ç†ã€æ•°å€¤è§£æã€‚

> **ğŸ“š æ ¹æ‹ ãƒ»å‡ºå…¸**
>
> * **IntelÂ® Intrinsics Guide (AVX2)**: `_mm256_add_ps` ãªã©ã®å‘½ä»¤ã«ã‚ˆã‚Šã€8ã¤ã®å˜ç²¾åº¦æµ®å‹•å°æ•°ç‚¹æ•°ã‚’1ã‚µã‚¤ã‚¯ãƒ«ï¼ˆã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆåŸºæº–ï¼‰ã§å‡¦ç†ã™ã‚‹ä»•æ§˜ã€‚
> * **Flynn's Taxonomy (1966)**: ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®åˆ†é¡ã«ãŠã„ã¦ã€å˜ä¸€ã®å‘½ä»¤ã‚¹ãƒˆãƒªãƒ¼ãƒ ã§è¤‡æ•°ã®ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’å‡¦ç†ã™ã‚‹ã€ŒSIMDã€ã®å®šç¾©ã€‚

---

## 3. GPU (Graphics Processing Unit)

**å‡¦ç†æ–¹å¼: SIMT (Single Instruction, Multiple Threads)**

NVIDIAãªã©ãŒæå”±ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚æ•°åƒã®ã‚³ã‚¢ï¼ˆCUDA Coreãªã©ï¼‰ãŒã€ãã‚Œãã‚Œç‹¬ç«‹ã—ãŸã‚¹ãƒ¬ãƒƒãƒ‰ã¨ã—ã¦åŒã˜å‘½ä»¤ã‚’ç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦å®Ÿè¡Œã—ã¾ã™ã€‚ãƒ¡ãƒ¢ãƒªãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã‚’éš è”½ã™ã‚‹ãŸã‚ã«ã€å¤§é‡ã®ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’ä¸¦åˆ—ç¨¼åƒã•ã›ã¾ã™ã€‚

* **è¦–è¦šè¡¨ç¾:** ã€Œé¢ï¼ˆå…¨ä½“ï¼‰ã€ãŒä¸€æ–‰ã«ç‚¹æ»…ã™ã‚‹ã€‚
* **å®Ÿè£…ãƒ­ã‚¸ãƒƒã‚¯:** Grid / Block / Thread éšå±¤ã‚’ç”¨ã„ãŸå…¨è¦ç´ ã«å¯¾ã™ã‚‹åŒæ™‚ã‚«ãƒ¼ãƒãƒ«å®Ÿè¡Œã€‚
* **è¨ˆç®—é‡ (Theoretical Cycles):** **1** (ä¸¦åˆ—åº¦å†…ã§ã‚ã‚Œã°)
* **ä¸»ãªç”¨é€”:** AIå­¦ç¿’ï¼ˆTrainingï¼‰ã€ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã€‚

> **ğŸ“š æ ¹æ‹ ãƒ»å‡ºå…¸**
>
> * **NVIDIA CUDA C++ Programming Guide**: SIMTã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®å®šç¾©ã€‚Warpï¼ˆ32ã‚¹ãƒ¬ãƒƒãƒ‰ã®æŸï¼‰å˜ä½ã§ã®åŒæ™‚å®Ÿè¡Œã¨ã€æ•°åƒã‚¹ãƒ¬ãƒƒãƒ‰ã¸ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ã®ä»•çµ„ã¿ã€‚
> * **NVIDIA Ampere / Hopper Architecture Whitepapers**: ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒãƒ«ãƒãƒ—ãƒ­ã‚»ãƒƒã‚µï¼ˆSMï¼‰å†…ã§ã®FP32æ¼”ç®—ã®ä¸¦åˆ—æ€§ã«é–¢ã™ã‚‹è¨˜è¿°ã€‚

---

## 4. TPU (Tensor Processing Unit)

**å‡¦ç†æ–¹å¼: ã‚·ã‚¹ãƒˆãƒªãƒƒã‚¯ã‚¢ãƒ¬ã‚¤ (Systolic Array)**

GoogleãŒé–‹ç™ºã—ãŸASICã§ã™ã€‚å„æ¼”ç®—ãƒ¦ãƒ‹ãƒƒãƒˆï¼ˆALUï¼‰ãŒæ ¼å­çŠ¶ã«ä¸¦ã³ã€ãƒ‡ãƒ¼ã‚¿ãŒå¿ƒè‡“ã®æ‹å‹•ï¼ˆSystoleï¼‰ã®ã‚ˆã†ã«éš£ã®ãƒ¦ãƒ‹ãƒƒãƒˆã¸å—ã‘æ¸¡ã•ã‚ŒãªãŒã‚‰ã€ãƒ¬ã‚¸ã‚¹ã‚¿ã¸ã®æ›¸ãæˆ»ã—ã‚’è¡Œã‚ãšã«é€£ç¶šçš„ã«ç©å’Œæ¼”ç®—ã‚’è¡Œã„ã¾ã™ã€‚

* **è¦–è¦šè¡¨ç¾:** ã€Œæ³¢ã€ãŒæ–œã‚ã«æµã‚Œã¦ã„ãã€‚
* **å®Ÿè£…ãƒ­ã‚¸ãƒƒã‚¯:** ãƒ‡ãƒ¼ã‚¿ã®å†åˆ©ç”¨ï¼ˆData Reuseï¼‰ã‚’æœ€å¤§åŒ–ã—ãŸãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å‡¦ç†ã€‚
* **è¨ˆç®—é‡ (Theoretical Cycles):** **10** (ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ®µæ•°ãƒ»è¡Œåˆ—ã‚µã‚¤ã‚ºä¾å­˜)
* **ä¸»ãªç”¨é€”:** å¤§è¦æ¨¡è¡Œåˆ—æ¼”ç®—ã€AIæ¨è«–ãƒ»å­¦ç¿’ã€‚

> **ğŸ“š æ ¹æ‹ ãƒ»å‡ºå…¸**
>
> * **Jouppi, N. P., et al. (Google), "In-Datacenter Performance Analysis of a Tensor Processing Unit" (ISCA 2017)**: TPUã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’åˆã‚ã¦è©³ç´°ã«å…¬é–‹ã—ãŸè«–æ–‡ã€‚ã‚·ã‚¹ãƒˆãƒªãƒƒã‚¯ã‚¢ãƒ¬ã‚¤ã‚’ç”¨ã„ã‚‹ã“ã¨ã§ã€æ±ç”¨CPU/GPUã«æ¯”ã¹ã¦ãƒ¡ãƒ¢ãƒªã‚¢ã‚¯ã‚»ã‚¹é »åº¦ã‚’åŠ‡çš„ã«æ¸›ã‚‰ã—ã€ãƒ¯ãƒƒãƒˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ãŒè§£èª¬ã•ã‚Œã¦ã„ã¾ã™ã€‚

---

## 5. NPU (Neural Processing Unit)

**å‡¦ç†æ–¹å¼: ã‚¿ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹å‡¦ç† / ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼æœ€é©åŒ– (Tile-based / Dataflow)**

ã‚¨ãƒƒã‚¸AIï¼ˆã‚¹ãƒãƒ›ã‚„IoTï¼‰å‘ã‘ã«ã€é™ã‚‰ã‚ŒãŸSRAMï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰ã‚’åŠ¹ç‡çš„ã«ä½¿ã†è¨­è¨ˆã§ã™ã€‚å¤§ããªè¡Œåˆ—ã‚’ã€Œã‚¿ã‚¤ãƒ«ã€ã«åˆ†å‰²ã—ã€ã‚ªãƒ³ãƒãƒƒãƒ—ãƒ¡ãƒ¢ãƒªå†…ã§å‡¦ç†ã‚’å®Œçµã•ã›ã¾ã™ã€‚ã¾ãŸã€å€¤ãŒ0ã®è¨ˆç®—ã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ã€Œã‚¹ãƒ‘ãƒ¼ã‚¹æ€§ï¼ˆSparsityï¼‰ã€ã‚„ã€é‡ã¿ã®åœ§ç¸®æŠ€è¡“ãªã©ãŒçµ„ã¿è¾¼ã¾ã‚Œã¾ã™ã€‚

* **è¦–è¦šè¡¨ç¾:** ã€Œãƒ–ãƒ­ãƒƒã‚¯ï¼ˆ5x5ã®å¡Šï¼‰ã€ãŒé †æ¬¡å‡¦ç†ã•ã‚Œã‚‹ã€‚
* **å®Ÿè£…ãƒ­ã‚¸ãƒƒã‚¯:** ç©ºé–“çš„ãªå±€æ‰€æ€§ï¼ˆSpatial Localityï¼‰ã‚’åˆ©ç”¨ã—ãŸãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°å‡¦ç†ã€‚
* **è¨ˆç®—é‡ (Theoretical Cycles):** **4** (åˆ†å‰²æ•°ä¾å­˜)
* **ä¸»ãªç”¨é€”:** ãƒ¢ãƒã‚¤ãƒ«ç«¯æœ«ã§ã®AIæ¨è«–ï¼ˆInferenceï¼‰ã€‚

> **ğŸ“š æ ¹æ‹ ãƒ»å‡ºå…¸**
>
> * **Sze, V., et al. (MIT), "Efficient Processing of Deep Neural Networks: A Tutorial and Survey" (Proceedings of the IEEE, 2017)**: AIã‚¢ã‚¯ã‚»ãƒ©ãƒ¬ãƒ¼ã‚¿ï¼ˆNPUï¼‰ã«ãŠã‘ã‚‹ã€ŒDataflowï¼ˆãƒ‡ãƒ¼ã‚¿ã®æµã‚Œï¼‰ã€ã®é‡è¦æ€§ã‚’èª¬ã„ãŸä»£è¡¨çš„ãªè«–æ–‡ã€‚ã‚¨ãƒãƒ«ã‚®ãƒ¼åŠ¹ç‡ã‚’é«˜ã‚ã‚‹ãŸã‚ã®ã€ŒTilingï¼ˆã‚¿ã‚¤ãƒªãƒ³ã‚°ï¼‰ã€ã‚„ã€ŒWeight Stationaryï¼ˆé‡ã¿å›ºå®šï¼‰ã€ã¨ã„ã£ãŸæ‰‹æ³•ãŒä½“ç³»åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚
> * **ARM Ethos-U NPU Technical Overview**: ãƒã‚¤ã‚¯ãƒ­NPUã«ãŠã‘ã‚‹MACï¼ˆç©å’Œæ¼”ç®—ï¼‰ãƒ¦ãƒ‹ãƒƒãƒˆã®æ§‹æˆã¨ã€SRAMã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚’æœ€é©åŒ–ã™ã‚‹ãŸã‚ã®ãƒ–ãƒ­ãƒƒã‚¯å‡¦ç†ã«é–¢ã™ã‚‹è¨˜è¿°ã€‚

---

### æ¯”è¼ƒã‚µãƒãƒª

| ãƒ—ãƒ­ã‚»ãƒƒã‚µ | å‡¦ç†å˜ä½ | å®Ÿè£…æ¦‚å¿µ | æŠ€è¡“çš„å‡ºå…¸ (Keyword) |
| :--- | :--- | :--- | :--- |
| **CPU** | Scalar | SISD, Sequential | Intel SDM (General Purpose) |
| **AVX2** | Vector | SIMD, Packing | Intel Intrinsics (YMM Registers) |
| **GPU** | Parallel | SIMT, Massive Threading | NVIDIA CUDA Guide (Warp/Grid) |
| **TPU** | Matrix | Systolic Array | Google ISCA 2017 Paper (Matrix Unit) |
| **NPU** | Block | Tiling, Dataflow | MIT "Efficient Processing" (Energy Efficiency) |
