# プロセッサ別 処理ロジックと実装仕様の比較・根拠 (2025 Revised)

本資料では、データ処理における各プロセッサアーキテクチャの計算手法、技術的根拠、およびデータの流れ（Flow）の違いを定義します。

## 1\. 汎用・高スループットアーキテクチャ (Conventional)

### 1-1. CPU (Central Processing Unit)

**処理方式: スカラ処理 (Scalar / SISD)**

汎用的な処理に特化しており、命令ごとにフェッチ・デコード・実行のサイクルを繰り返します。

  * **視覚表現:** 「点」が1マスずつ不規則に移動する。
  * **実装ロジック:** 複雑な分岐予測とキャッシュ階層による逐次処理。
  * **計算量:** **100** (Theoretical Cycles)
  * **弱点:** コンテキストスイッチやキャッシュミスによる「ストール（待機時間）」が発生しやすい。

> **📚 根拠:** *Intel® 64 and IA-32 Architectures Software Developer’s Manual*

### 1-2. GPU (Graphics Processing Unit)

**処理方式: SIMT (Single Instruction, Multiple Threads)**

大量のコアが同じ命令を異なるデータに対して同時に実行します。メモリレイテンシを隠蔽するために数千のスレッドを切り替えます。

  * **視覚表現:** 「面（全体）」が一斉に点滅する。
  * **実装ロジック:** HBM (High Bandwidth Memory) への依存度が高い並列カーネル実行。
  * **計算量:** **1** (Parallelism limit)
  * **弱点:** データ転送のボトルネック。DRAMへのアクセス集中による遅延。

> **📚 根拠:** *NVIDIA CUDA Programming Guide / Ampere Whitepaper*

-----

## 2\. AI特化型アーキテクチャ (AI Accelerators)

### 2-1. TPU (Tensor Processing Unit)

**処理方式: シストリックアレイ (Systolic Array)**

Googleが開発。心臓の拍動のようにデータを演算ユニット間で受け渡します。レジスタへの書き戻しを省略し、電力効率を最大化します。

  * **視覚表現:** 「波」が斜めに流れていく。
  * **実装ロジック:** マトリクス積和演算（MXU）におけるデータの再利用（Data Reuse）。
  * **計算量:** **10** (Pipeline depth)

> **📚 根拠:** *Jouppi et al., "In-Datacenter Performance Analysis of a TPU" (ISCA 2017)*

### 2-2. NPU (Neural Processing Unit)

**処理方式: タイルベース・データフロー (Tile-based / Dataflow)**

エッジデバイス向け。限られたSRAMを効率的に使うため、大きな行列を小さなブロック（タイル）に分割して処理します。

  * **視覚表現:** 「ブロック」単位で順次処理が進む。
  * **実装ファイル:** `processing_complexity_npu.gif`
  * **実装ロジック:** 空間的局所性を利用したブロッキングとスパース性（ゼロ値スキップ）の活用。

> **📚 根拠:** *MIT "Efficient Processing of Deep Neural Networks" (2017)*

-----

## 3\. 次世代：決定論的アーキテクチャ (The New Wave)

### 3-1. LPU (Language Processing Unit)

**処理方式: 決定論的実行 (Deterministic Execution)**

Groqなどが提唱。ハードウェアによる動的なスケジューリング（キャッシュ、分岐予測、アウトオブオーダー実行）を完全に排除し、**コンパイラが全てのデータの動きとタイミングを事前にスケジューリング**します。

  * **特徴:**
      * **No Stalls:** メモリ待ち合わせによる停止が発生しない。
      * **Zero Jitter:** 処理時間が常に一定であり、予測可能。
  * **実装ファイル:** `processor_simulation.gif` (Left Side)

-----

## 4\. 動作シミュレーション比較 (Visual Analysis)

生成されたGIFシミュレーションによる挙動の差異を以下に解説します。

### A. LPU vs Traditional Simulation (`processor_simulation.gif`)

| 項目 | LPU (左画面) | CPU/GPU Traditional (右画面) |
| :--- | :--- | :--- |
| **データの流れ** | **Fluid (流体的)**<br>青い波が止まることなく一定のリズムで流れ続ける。 | **Burst & Stall (断続的)**<br>処理（オレンジ）と停止（赤/Stall）がランダムに発生する。 |
| **制御主体** | **Software (Compiler)**<br>コンパイル時にデータの「位置」と「時間」が確定している。 | **Hardware**<br>実行時にキャッシュミスやメモリ競合をハードウェアが管理・調停する。 |
| **遅延 (Latency)** | **定数 (Constant)** | **確率的 (Probabilistic)** |

### B. NPU Processing flow (`processing_complexity_npu.gif`)

  * **挙動:** 巨大なデータ全体を一度に扱うのではなく、5x5などの「タイル」単位で計算が完了していく様子。
  * **技術的意味:** オフチップメモリ（DRAM）へのアクセス回数を減らし、オンチップバッファ（SRAM）内で計算を完結させる省電力設計を視覚化しています。

-----

## まとめ：プロセッサ進化の方向性

| 世代 | キーワード | 代表プロセッサ | アプローチ |
| :--- | :--- | :--- | :--- |
| **Gen 1** | **汎用性** | CPU | どんな計算でもできるが、並列処理は遅い。 |
| **Gen 2** | **スループット** | GPU | 大量のデータを同時に捌くが、メモリの壁に当たる。 |
| **Gen 3** | **効率性** | TPU / NPU | 行列演算に特化し、データの移動を最小化する。 |
| **Gen 4** | **決定論** | **LPU** | 複雑さをハードからソフト（コンパイラ）へ移し、\*\*「待ち時間ゼロ」\*\*を実現する。 |